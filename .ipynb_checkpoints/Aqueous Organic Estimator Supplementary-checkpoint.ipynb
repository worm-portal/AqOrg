{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aqueous Organic Estimator Supplementary Notebook\n",
    "\n",
    "Authors: Grayson Boyer, Vincent Milesi\n",
    "\n",
    "A notebook for estimating hydration properties of molecules from scratch. Breaks molecules with known properties into second-order groups, solves for the contribution of each group with multilinear regression, and then estimates the properties of molecules from those groups.\n",
    "\n",
    "Date modified: 10/13/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Alkene_Hydration_Properties_no_ethene_groups.csv'\n",
    "props = [\"dhCp\", \"dhH\", \"dhG\", \"Vh\"]\n",
    "sig_figs = 3\n",
    "\n",
    "fixed_material_point = True # use a fixed material point when estimating group contributions?\n",
    "estimate_material_point = False # estimate a material point from available data? Valid only if fixed_material_point = False.\n",
    "material_point_dict = {\"dhG\":7.95, \"dhH\":-2.29, \"dhCp\":0, \"Vh\":1.12} # material point value. Valid only if fixed_material_point = True. Values taken from Plyasunov and Shock 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jroba\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1650: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "C:\\Users\\jroba\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\statsmodels\\base\\model.py:1452: RuntimeWarning: invalid value encountered in multiply\n",
      "  cov_p = self.normalized_cov_params * scale\n",
      "C:\\Users\\jroba\\anaconda3\\envs\\my-rdkit-env\\lib\\site-packages\\ipykernel_launcher.py:130: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'numpy.float64'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-19305241dcaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;31m# =============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-19305241dcaf>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mmaterial_point\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mgroup_property_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig_figs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaterial_point\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-19305241dcaf>\u001b[0m in \u001b[0;36mgroup_property_estimator\u001b[1;34m(file_name, dependent_param, sf, material_point)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mpred_errs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_group\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgroup_property_se_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mtopred_errs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_group\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgroup_property_se_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_topred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_topred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_topred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-19305241dcaf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mpred_errs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_group\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgroup_property_se_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mtopred_errs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_group\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgroup_property_se_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_topred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_topred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_topred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-19305241dcaf>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0mpred_errs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_group\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgroup_property_se_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mtopred_errs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_group\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgroup_property_se_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn_group\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_topred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_topred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_topred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'numpy.float64'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov 27 09:36:15 2018\n",
    "Modified on Mar 21, 2019 by Grayson\n",
    "\n",
    "@author: Vincent\n",
    "@author: Grayson\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "#                               IMPORT PACKAGES\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from math import floor, log10 # for significant figure rounding\n",
    "import statsmodels.api as sm # for multilinear regression\n",
    "from string import ascii_lowercase\n",
    "import itertools\n",
    "\n",
    "# =============================================================================\n",
    "#                                     MAIN\n",
    "# =============================================================================\n",
    "def main():\n",
    "    for prop in props:\n",
    "        if fixed_material_point:\n",
    "            material_point = material_point_dict[prop]\n",
    "        else:\n",
    "            material_point = 0\n",
    "        group_property_estimator(file_name, prop, sig_figs, material_point)\n",
    "    \n",
    "    \n",
    "# =============================================================================\n",
    "#                                  FUNCTIONS\n",
    "# =============================================================================\n",
    "round_to_n = lambda x, n: round(x, -int(floor(log10(abs(x)))) + (n - 1))\n",
    "\n",
    "def iter_all_strings():\n",
    "    for size in itertools.count(1):\n",
    "        for s in itertools.product(ascii_lowercase, repeat=size):\n",
    "            yield \"\".join(s)\n",
    "\n",
    "def group_property_estimator(file_name, dependent_param, sf, material_point):   \n",
    "    df_data = pd.read_csv(file_name, index_col=0)  \n",
    "    \n",
    "    # remove rows with containing only NaN\n",
    "    df_data = df_data[np.isfinite(df_data[df_data.columns.values[len(df_data.columns.values)-1]])]\n",
    "    \n",
    "    # remove columns containing 0 groups\n",
    "    df_data = df_data.loc[:, (df_data != 0).any(axis=0)]\n",
    "    \n",
    "    # get data subset that needs a prediction\n",
    "    df_topred = df_data[np.isfinite(df_data[dependent_param]) == False]\n",
    "    \n",
    "    # remove rows without y values\n",
    "    df_data = df_data[np.isfinite(df_data[dependent_param])]\n",
    "    \n",
    "    ## define the independent parameter\n",
    "    X = df_data[[x for x in list(df_data.columns.values) if not x in [\"compound\", \"formula\", dependent_param]+props]]\n",
    "    \n",
    "    ## define the dependent parameter\n",
    "    y = df_data[dependent_param]\n",
    "    \n",
    "    # get X of molecules to predict\n",
    "    X_topred = df_topred[[x for x in list(df_topred.columns.values) if not x in [\"compound\", \"formula\", dependent_param]+props]]\n",
    "\n",
    "    if not fixed_material_point:\n",
    "\n",
    "        ## add an intercept to the multi reg\n",
    "        if estimate_material_point:\n",
    "            X[\"material point\"] = 1\n",
    "            X_topred[\"material point\"] = 1\n",
    "\n",
    "        multi_reg = sm.OLS(y[0:], X[0:]).fit() # perform the multiple regression\n",
    "        prediction = multi_reg.predict(X) # make the predictions from the multi_reg\n",
    "        preds = multi_reg.predict(X_topred)\n",
    "        \n",
    "        # set these variables to 0 regardless of whether material point is being estimated\n",
    "        material_point = 0 \n",
    "        material_point_err = 0\n",
    "        \n",
    "    else:\n",
    "        from statsmodels.formula.api import ols\n",
    "        \n",
    "        # subtract material point from y values (dependent params)\n",
    "        df_data[\"y_minus_Yo\"] = df_data[dependent_param] - material_point\n",
    "        \n",
    "        # ols formulas can't handle SMARTS strings as variables,\n",
    "        # so store them in a dictionary of simpler strings (generated iteratively)\n",
    "        # in the form {label:SMARTS}\n",
    "        label_dict = {}\n",
    "        X_vars = list(X.columns.values)\n",
    "        for i,s in enumerate(itertools.islice(iter_all_strings(), len(X_vars))):\n",
    "            label_dict[s] = X_vars[i]\n",
    "        \n",
    "        # create an inverse label dictionary {SMARTS:label}\n",
    "        inv_label_dict = {v: k for k, v in label_dict.items()}\n",
    "        \n",
    "        # rename dependent variable columns with new labels\n",
    "        X = X.rename(columns=inv_label_dict)\n",
    "        X_topred = X_topred.rename(columns=inv_label_dict)\n",
    "        df_data = df_data.rename(columns=inv_label_dict)\n",
    "        \n",
    "        formula_str = \"y_minus_Yo ~ \" + \" + \".join(list(X.columns.values)) + \" -1\"\n",
    "\n",
    "        multi_reg = ols(formula=formula_str, data=df_data).fit()\n",
    "        prediction = multi_reg.predict(X) # make the predictions from the multi_reg\n",
    "        preds = multi_reg.predict(X_topred)\n",
    "        \n",
    "        # restore dependent variable column names\n",
    "        X = X.rename(columns=label_dict)\n",
    "        X_topred = X_topred.rename(columns=label_dict)\n",
    "        df_data = df_data.rename(columns=label_dict)\n",
    "        \n",
    "        \n",
    "#     print(multi_reg.summary()) # print out the statistics\n",
    "#     print(multi_reg.params) \n",
    "#     print(multi_reg.params.values) # print param as an array\n",
    "\n",
    "    group_property_dict = dict(zip(X.columns.values, [round(val, 4) for val in multi_reg.params.values]))\n",
    "\n",
    "    group_property_se_dict = dict(zip(X.columns.values, [round(val, 4) for val in multi_reg.bse.values]))\n",
    "\n",
    "    if fixed_material_point:\n",
    "        group_property_dict[\"material_point\"] = material_point\n",
    "        group_property_se_dict[\"material_point\"] = 0 # material point uncertainty fixed at 0 (see Plyasunov and Shock 2000)\n",
    "\n",
    "        \n",
    "    pred_errs = [sum([n_group*group_property_se_dict[group]**2 for n_group, group in zip(X.loc[idx], X.columns.values)])**0.5 for idx in X.index]\n",
    "\n",
    "    topred_errs = [sum([n_group*group_property_se_dict[group]**2 for n_group, group in zip(X_topred.loc[idx], X_topred.columns.values)])**0.5 for idx in X_topred.index]\n",
    "\n",
    "\n",
    "    comp_pred_df = pd.DataFrame({\"actual\":df_data[dependent_param],\n",
    "                                 \"prediction\":[round(pred+material_point, 2) for pred in prediction.values],\n",
    "                                 \"pred errs\":[round(err, 2) for err in pred_errs]})\n",
    "\n",
    "    df_preds = pd.DataFrame({\"actual\":df_topred[dependent_param],\n",
    "                                 \"prediction\":[round(pred+material_point, 2) for pred in preds.values],\n",
    "                                 \"pred errs\":[round(err, 2) for err in topred_errs]})\n",
    "\n",
    "    df_final = comp_pred_df.append(pd.DataFrame(data = df_preds))\n",
    "\n",
    "    print(\"\\nPredicted group contributions for \" + dependent_param + \":\")\n",
    "    print(group_property_dict)\n",
    "    print(\"\\nPredicted standard error of group contributions for \" + dependent_param + \":\")\n",
    "    print(group_property_se_dict)\n",
    "    print(\"\\nPredictions for \" + dependent_param + \":\")\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(df_final)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# =============================================================================\n",
    "#                                CALL MAIN\n",
    "# =============================================================================\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
